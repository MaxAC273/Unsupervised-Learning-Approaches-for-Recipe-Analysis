{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d2455ce",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72a859e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_5228/1424031022.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['name_tokens'] = X['name_tokens'].apply(lambda x: eval(x))  # Convert string representation to list\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_5228/1424031022.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ingredient_tokens'] = X['ingredient_tokens'].apply(lambda x: eval(x))\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_5228/1424031022.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['steps_tokens'] = X['steps_tokens'].apply(lambda x: eval(x))\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_5228/1424031022.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['name_length'] = X['name_tokens'].apply(len)\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_5228/1424031022.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ingredient_count'] = X['ingredient_tokens'].apply(len)\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_5228/1424031022.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['steps_length'] = X['steps_tokens'].apply(len)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Calorie Level Prediction: 0.39048607410316105\n",
      "\n",
      "Classification Report for Calorie Level Prediction:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.53      0.48     13934\n",
      "           1       0.38      0.37      0.38     12785\n",
      "           2       0.29      0.20      0.24      8934\n",
      "\n",
      "    accuracy                           0.39     35653\n",
      "   macro avg       0.37      0.37      0.36     35653\n",
      "weighted avg       0.38      0.39      0.38     35653\n",
      "\n",
      "\n",
      "Confusion Matrix for Calorie Level Prediction:\n",
      " [[7344 4582 2008]\n",
      " [5680 4755 2350]\n",
      " [3904 3207 1823]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('nutritional_clustered_data.csv')\n",
    "\n",
    "# Extract features (X) and target variables (y)\n",
    "X = data[['name_tokens', 'ingredient_tokens', 'steps_tokens', 'techniques', 'ingredient_ids']]\n",
    "y_calorie_level = data['calorie_level']\n",
    "y_nutritional_cluster = data['nutritional_cluster']\n",
    "\n",
    "# Tokenization and Preprocessing\n",
    "X['name_tokens'] = X['name_tokens'].apply(lambda x: eval(x))  # Convert string representation to list\n",
    "X['ingredient_tokens'] = X['ingredient_tokens'].apply(lambda x: eval(x))\n",
    "X['steps_tokens'] = X['steps_tokens'].apply(lambda x: eval(x))\n",
    "\n",
    "# Feature Engineering\n",
    "X['name_length'] = X['name_tokens'].apply(len)\n",
    "X['ingredient_count'] = X['ingredient_tokens'].apply(len)\n",
    "X['steps_length'] = X['steps_tokens'].apply(len)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_calorie_train, y_calorie_test, y_cluster_train, y_cluster_test = train_test_split(\n",
    "    X, y_calorie_level, y_nutritional_cluster, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Random Forest Classifier for Calorie Level Prediction\n",
    "rf_calorie = RandomForestClassifier(random_state=42, n_jobs=-1)  # n_jobs=-1 for parallel processing\n",
    "\n",
    "# Fit the model\n",
    "rf_calorie.fit(X_train[['name_length', 'ingredient_count', 'steps_length']], y_calorie_train)\n",
    "\n",
    "# Evaluate the model for Calorie Level Prediction\n",
    "y_calorie_pred = rf_calorie.predict(X_test[['name_length', 'ingredient_count', 'steps_length']])\n",
    "accuracy_calorie = accuracy_score(y_calorie_test, y_calorie_pred)\n",
    "\n",
    "print(\"Accuracy for Calorie Level Prediction:\", accuracy_calorie)\n",
    "print(\"\\nClassification Report for Calorie Level Prediction:\\n\", classification_report(y_calorie_test, y_calorie_pred))\n",
    "print(\"\\nConfusion Matrix for Calorie Level Prediction:\\n\", confusion_matrix(y_calorie_test, y_calorie_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85dd53df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Nutritional Cluster Prediction: 0.3035929655288475\n",
      "\n",
      "Classification Report for Nutritional Cluster Prediction:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.05      0.06      3266\n",
      "           1       0.28      0.29      0.28      8934\n",
      "           2       0.12      0.05      0.07      3430\n",
      "           3       0.36      0.48      0.41     10504\n",
      "           4       0.29      0.30      0.30      9519\n",
      "\n",
      "    accuracy                           0.30     35653\n",
      "   macro avg       0.23      0.23      0.23     35653\n",
      "weighted avg       0.28      0.30      0.29     35653\n",
      "\n",
      "\n",
      "Confusion Matrix for Nutritional Cluster Prediction:\n",
      " [[ 148  841  161 1264  852]\n",
      " [ 372 2558  432 3037 2535]\n",
      " [ 160  937  178 1191  964]\n",
      " [ 311 2222  335 5066 2570]\n",
      " [ 324 2588  364 3369 2874]]\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering for Nutritional Cluster Prediction\n",
    "X['techniques_count'] = X['techniques'].apply(lambda x: eval(x)).apply(len)\n",
    "X['ingredient_ids_count'] = X['ingredient_ids'].apply(lambda x: eval(x)).apply(len)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_calorie_train, y_calorie_test, y_cluster_train, y_cluster_test = train_test_split(\n",
    "    X, y_calorie_level, y_nutritional_cluster, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Random Forest Classifier for Nutritional Cluster Prediction\n",
    "rf_cluster = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "rf_cluster.fit(X_train[['name_length', 'ingredient_count', 'steps_length', 'techniques_count', 'ingredient_ids_count']],\n",
    "               y_cluster_train)\n",
    "\n",
    "# Evaluate the model for Nutritional Cluster Prediction\n",
    "y_cluster_pred = rf_cluster.predict(X_test[['name_length', 'ingredient_count', 'steps_length', 'techniques_count', 'ingredient_ids_count']])\n",
    "accuracy_cluster = accuracy_score(y_cluster_test, y_cluster_pred)\n",
    "\n",
    "print(\"Accuracy for Nutritional Cluster Prediction:\", accuracy_cluster)\n",
    "print(\"\\nClassification Report for Nutritional Cluster Prediction:\\n\", classification_report(y_cluster_test, y_cluster_pred))\n",
    "print(\"\\nConfusion Matrix for Nutritional Cluster Prediction:\\n\", confusion_matrix(y_cluster_test, y_cluster_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e99451",
   "metadata": {},
   "source": [
    "# SVM model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8924ac08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_5228/4147770823.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['name_tokens'] = X['name_tokens'].apply(lambda x: eval(x))\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_5228/4147770823.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ingredient_tokens'] = X['ingredient_tokens'].apply(lambda x: eval(x))\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_5228/4147770823.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['steps_tokens'] = X['steps_tokens'].apply(lambda x: eval(x))\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_5228/4147770823.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['name_length'] = X['name_tokens'].apply(len)\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_5228/4147770823.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ingredient_count'] = X['ingredient_tokens'].apply(len)\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_5228/4147770823.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['steps_length'] = X['steps_tokens'].apply(len)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('nutritional_clustered_data.csv')\n",
    "\n",
    "# Extract features (X) and target variables (y)\n",
    "X = data[['name_tokens', 'ingredient_tokens', 'steps_tokens', 'techniques', 'ingredient_ids']]\n",
    "y_calorie_level = data['calorie_level']\n",
    "y_nutritional_cluster = data['nutritional_cluster']\n",
    "\n",
    "# Tokenization and Preprocessing\n",
    "X['name_tokens'] = X['name_tokens'].apply(lambda x: eval(x))\n",
    "X['ingredient_tokens'] = X['ingredient_tokens'].apply(lambda x: eval(x))\n",
    "X['steps_tokens'] = X['steps_tokens'].apply(lambda x: eval(x))\n",
    "\n",
    "# Feature Engineering\n",
    "X['name_length'] = X['name_tokens'].apply(len)\n",
    "X['ingredient_count'] = X['ingredient_tokens'].apply(len)\n",
    "X['steps_length'] = X['steps_tokens'].apply(len)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_calorie_train, y_calorie_test, y_cluster_train, y_cluster_test = train_test_split(\n",
    "    X, y_calorie_level, y_nutritional_cluster, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# SVM Classifier for Calorie Level Prediction (Linear Kernel)\n",
    "svm_calorie = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "svm_calorie.fit(X_train[['name_length', 'ingredient_count', 'steps_length']], y_calorie_train)\n",
    "\n",
    "# Evaluate the model for Calorie Level Prediction\n",
    "y_calorie_pred = svm_calorie.predict(X_test[['name_length', 'ingredient_count', 'steps_length']])\n",
    "accuracy_calorie = accuracy_score(y_calorie_test, y_calorie_pred)\n",
    "\n",
    "print(\"Accuracy for Calorie Level Prediction (Linear SVM):\", accuracy_calorie)\n",
    "print(\"\\nClassification Report for Calorie Level Prediction (Linear SVM):\\n\", classification_report(y_calorie_test, y_calorie_pred))\n",
    "print(\"\\nConfusion Matrix for Calorie Level Prediction (Linear SVM):\\n\", confusion_matrix(y_calorie_test, y_calorie_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947fdff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c00e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_10969/1613250964.py:32: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return pd.DataFrame(data, columns=['techniques', 'ingredient_ids']).applymap(lambda x: eval(x)[0])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('nutritional_clustered_data.csv')\n",
    "\n",
    "# Extract features (X) and target variables (y)\n",
    "X = data[['name_tokens', 'ingredient_tokens', 'steps_tokens', 'techniques', 'ingredient_ids']]\n",
    "y_calorie_level = data['calorie_level']\n",
    "y_nutritional_cluster = data['nutritional_cluster']\n",
    "\n",
    "# Tokenization and Preprocessing\n",
    "def tokenize_and_preprocess(column):\n",
    "    return column.apply(lambda x: ' '.join(eval(x)) if isinstance(x, str) else '')\n",
    "\n",
    "preprocessor_text = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('name_tokens', CountVectorizer(), 'name_tokens'),\n",
    "        ('ingredient_tokens', CountVectorizer(), 'ingredient_tokens'),\n",
    "        ('steps_tokens', CountVectorizer(), 'steps_tokens'),\n",
    "    ])\n",
    "\n",
    "# Custom transformer to convert 'other_features' to numeric\n",
    "def convert_to_numeric(data):\n",
    "    return pd.DataFrame(data, columns=['techniques', 'ingredient_ids']).applymap(lambda x: eval(x)[0])\n",
    "\n",
    "preprocessor_other = FunctionTransformer(convert_to_numeric, validate=False)\n",
    "\n",
    "# Combine the two transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', preprocessor_text, X.columns[:3]),\n",
    "        ('other', preprocessor_other, X.columns[3:])\n",
    "    ])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_calorie_train, y_calorie_test, y_cluster_train, y_cluster_test = train_test_split(\n",
    "    X, y_calorie_level, y_nutritional_cluster, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# SVM Classifier for Calorie Level Prediction (Linear Kernel)\n",
    "classifier = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "\n",
    "# Example of using a different classifier (Random Forest)\n",
    "# classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "pipeline.fit(X_train, y_calorie_train)\n",
    "\n",
    "# Evaluate the model for Calorie Level Prediction\n",
    "y_calorie_pred = pipeline.predict(X_test)\n",
    "accuracy_calorie = accuracy_score(y_calorie_test, y_calorie_pred)\n",
    "\n",
    "print(\"Accuracy for Calorie Level Prediction:\", accuracy_calorie)\n",
    "print(\"\\nClassification Report for Calorie Level Prediction:\\n\", classification_report(y_calorie_test, y_calorie_pred))\n",
    "print(\"\\nConfusion Matrix for Calorie Level Prediction:\\n\", confusion_matrix(y_calorie_test, y_calorie_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747e85e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "346de9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_12545/893174606.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['name_tokens'] = X['name_tokens'].apply(lambda x: eval(x))  # Convert string representation to list\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_12545/893174606.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ingredient_tokens'] = X['ingredient_tokens'].apply(lambda x: eval(x))\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_12545/893174606.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['steps_tokens'] = X['steps_tokens'].apply(lambda x: eval(x))\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_12545/893174606.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['name_length'] = X['name_tokens'].apply(len)\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_12545/893174606.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ingredient_count'] = X['ingredient_tokens'].apply(len)\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_12545/893174606.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['steps_length'] = X['steps_tokens'].apply(len)\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_12545/893174606.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[numerical_features] = scaler.fit_transform(X[numerical_features])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Calorie Level Prediction: 0.43516674613637\n",
      "\n",
      "Classification Report for Calorie Level Prediction:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.67      0.55     13934\n",
      "           1       0.40      0.45      0.42     12785\n",
      "           2       0.44      0.05      0.08      8934\n",
      "\n",
      "    accuracy                           0.44     35653\n",
      "   macro avg       0.43      0.39      0.35     35653\n",
      "weighted avg       0.43      0.44      0.39     35653\n",
      "\n",
      "\n",
      "Confusion Matrix for Calorie Level Prediction:\n",
      " [[9404 4383  147]\n",
      " [6709 5701  375]\n",
      " [4333 4191  410]]\n",
      "\n",
      "Accuracy for Nutritional Cluster Prediction: 0.3552015258183042\n",
      "\n",
      "Classification Report for Nutritional Cluster Prediction:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      3266\n",
      "           1       0.32      0.32      0.32      8934\n",
      "           2       0.00      0.00      0.00      3430\n",
      "           3       0.38      0.66      0.48     10504\n",
      "           4       0.33      0.30      0.32      9519\n",
      "\n",
      "    accuracy                           0.36     35653\n",
      "   macro avg       0.21      0.26      0.22     35653\n",
      "weighted avg       0.28      0.36      0.31     35653\n",
      "\n",
      "\n",
      "Confusion Matrix for Nutritional Cluster Prediction:\n",
      " [[   0  984    0 1684  598]\n",
      " [   0 2886    0 3695 2353]\n",
      " [   0 1009    0 1575  846]\n",
      " [   0 1569    0 6908 2027]\n",
      " [   0 2446    0 4203 2870]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('nutritional_clustered_data.csv')\n",
    "\n",
    "# Extract features (X) and target variables (y)\n",
    "X = data[['name_tokens', 'ingredient_tokens', 'steps_tokens', 'techniques', 'ingredient_ids']]\n",
    "y_calorie_level = data['calorie_level']\n",
    "y_nutritional_cluster = data['nutritional_cluster']\n",
    "\n",
    "# Tokenization and Preprocessing\n",
    "X['name_tokens'] = X['name_tokens'].apply(lambda x: eval(x))  # Convert string representation to list\n",
    "X['ingredient_tokens'] = X['ingredient_tokens'].apply(lambda x: eval(x))\n",
    "X['steps_tokens'] = X['steps_tokens'].apply(lambda x: eval(x))\n",
    "\n",
    "# Feature Engineering\n",
    "X['name_length'] = X['name_tokens'].apply(len)\n",
    "X['ingredient_count'] = X['ingredient_tokens'].apply(len)\n",
    "X['steps_length'] = X['steps_tokens'].apply(len)\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['name_length', 'ingredient_count', 'steps_length']\n",
    "X[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_calorie_train, y_calorie_test, y_cluster_train, y_cluster_test = train_test_split(\n",
    "    X, y_calorie_level, y_nutritional_cluster, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# SVM for Calorie Level Prediction\n",
    "svm_calorie = SVC(random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "svm_calorie.fit(X_train[numerical_features], y_calorie_train)\n",
    "\n",
    "# Evaluate the model for Calorie Level Prediction\n",
    "y_calorie_pred = svm_calorie.predict(X_test[numerical_features])\n",
    "accuracy_calorie = accuracy_score(y_calorie_test, y_calorie_pred)\n",
    "\n",
    "print(\"Accuracy for Calorie Level Prediction:\", accuracy_calorie)\n",
    "print(\"\\nClassification Report for Calorie Level Prediction:\\n\", classification_report(y_calorie_test, y_calorie_pred))\n",
    "print(\"\\nConfusion Matrix for Calorie Level Prediction:\\n\", confusion_matrix(y_calorie_test, y_calorie_pred))\n",
    "\n",
    "# SVM for Nutritional Cluster Prediction\n",
    "svm_cluster = SVC(random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "svm_cluster.fit(X_train[numerical_features], y_cluster_train)\n",
    "\n",
    "# Evaluate the model for Nutritional Cluster Prediction\n",
    "y_cluster_pred = svm_cluster.predict(X_test[numerical_features])\n",
    "accuracy_cluster = accuracy_score(y_cluster_test, y_cluster_pred)\n",
    "\n",
    "print(\"\\nAccuracy for Nutritional Cluster Prediction:\", accuracy_cluster)\n",
    "print(\"\\nClassification Report for Nutritional Cluster Prediction:\\n\", classification_report(y_cluster_test, y_cluster_pred))\n",
    "print(\"\\nConfusion Matrix for Nutritional Cluster Prediction:\\n\", confusion_matrix(y_cluster_test, y_cluster_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9801deee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdf168f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_12545/1415960566.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['name_tokens'] = X['name_tokens'].apply(lambda x: eval(x))\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_12545/1415960566.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ingredient_tokens'] = X['ingredient_tokens'].apply(lambda x: eval(x))\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_12545/1415960566.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['steps_tokens'] = X['steps_tokens'].apply(lambda x: eval(x))\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_12545/1415960566.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['name_length'] = X['name_tokens'].apply(len)\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_12545/1415960566.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ingredient_count'] = X['ingredient_tokens'].apply(len)\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_12545/1415960566.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['steps_length'] = X['steps_tokens'].apply(len)\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_12545/1415960566.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[numerical_features] = scaler.fit_transform(X[numerical_features])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy for Calorie Level Prediction: 0.40380166771272297\n",
      "Accuracy for Calorie Level Prediction: 0.410933161304799\n",
      "\n",
      "Classification Report for Calorie Level Prediction:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.54      0.51     13934\n",
      "           1       0.39      0.30      0.34     12785\n",
      "           2       0.32      0.36      0.34      8934\n",
      "\n",
      "    accuracy                           0.41     35653\n",
      "   macro avg       0.40      0.40      0.40     35653\n",
      "weighted avg       0.41      0.41      0.41     35653\n",
      "\n",
      "\n",
      "Confusion Matrix for Calorie Level Prediction:\n",
      " [[7585 3544 2805]\n",
      " [5033 3842 3910]\n",
      " [3166 2544 3224]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [167295, 142612]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m svm_cluster \u001b[38;5;241m=\u001b[39m SVC(C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)  \u001b[38;5;66;03m# Add hyperparameters for tuning\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m svm_cluster\u001b[38;5;241m.\u001b[39mfit(X_train_resampled, y_cluster_train)  \u001b[38;5;66;03m# Use resampled data for training\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Evaluate the model for Nutritional Cluster Prediction using cross-validation\u001b[39;00m\n\u001b[1;32m     60\u001b[0m cv_accuracy_cluster \u001b[38;5;241m=\u001b[39m cross_val_score(svm_cluster, X_train_resampled, y_cluster_train, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:190\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    188\u001b[0m     check_consistent_length(X, y)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    191\u001b[0m         X,\n\u001b[1;32m    192\u001b[0m         y,\n\u001b[1;32m    193\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64,\n\u001b[1;32m    194\u001b[0m         order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    195\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    196\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    197\u001b[0m     )\n\u001b[1;32m    199\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_targets(y)\n\u001b[1;32m    201\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[1;32m    202\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[1;32m    203\u001b[0m )\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/sklearn/base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1164\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1146\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1147\u001b[0m     X,\n\u001b[1;32m   1148\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1160\u001b[0m )\n\u001b[1;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m-> 1164\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    405\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    410\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [167295, 142612]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler  # Import oversampling library\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('nutritional_clustered_data.csv')\n",
    "\n",
    "# Extract features (X) and target variables (y)\n",
    "X = data[['name_tokens', 'ingredient_tokens', 'steps_tokens', 'techniques', 'ingredient_ids']]\n",
    "y_calorie_level = data['calorie_level']\n",
    "y_nutritional_cluster = data['nutritional_cluster']\n",
    "\n",
    "# Tokenization and Preprocessing\n",
    "X['name_tokens'] = X['name_tokens'].apply(lambda x: eval(x))\n",
    "X['ingredient_tokens'] = X['ingredient_tokens'].apply(lambda x: eval(x))\n",
    "X['steps_tokens'] = X['steps_tokens'].apply(lambda x: eval(x))\n",
    "\n",
    "# Feature Engineering\n",
    "X['name_length'] = X['name_tokens'].apply(len)\n",
    "X['ingredient_count'] = X['ingredient_tokens'].apply(len)\n",
    "X['steps_length'] = X['steps_tokens'].apply(len)\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['name_length', 'ingredient_count', 'steps_length']\n",
    "X[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
    "\n",
    "# Check for class imbalance and apply oversampling to the training set\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_calorie_train_resampled = oversampler.fit_resample(X_train[numerical_features], y_calorie_train)\n",
    "\n",
    "# SVM for Calorie Level Prediction with hyperparameter tuning\n",
    "svm_calorie = SVC(C=1.0, kernel='rbf', random_state=42)  # Add hyperparameters for tuning\n",
    "\n",
    "# Fit the model using resampled data\n",
    "svm_calorie.fit(X_train_resampled, y_calorie_train_resampled)\n",
    "\n",
    "# Evaluate the model for Calorie Level Prediction using cross-validation\n",
    "cv_accuracy_calorie = cross_val_score(svm_calorie, X_train_resampled, y_calorie_train_resampled, cv=5, scoring='accuracy')\n",
    "print(\"Cross-Validation Accuracy for Calorie Level Prediction:\", cv_accuracy_calorie.mean())\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_calorie_pred = svm_calorie.predict(X_test[numerical_features])\n",
    "accuracy_calorie = accuracy_score(y_calorie_test, y_calorie_pred)\n",
    "\n",
    "print(\"Accuracy for Calorie Level Prediction:\", accuracy_calorie)\n",
    "print(\"\\nClassification Report for Calorie Level Prediction:\\n\", classification_report(y_calorie_test, y_calorie_pred))\n",
    "print(\"\\nConfusion Matrix for Calorie Level Prediction:\\n\", confusion_matrix(y_calorie_test, y_calorie_pred))\n",
    "\n",
    "# SVM for Nutritional Cluster Prediction with hyperparameter tuning\n",
    "svm_cluster = SVC(C=1.0, kernel='rbf', random_state=42)  # Add hyperparameters for tuning\n",
    "\n",
    "# Fit the model\n",
    "svm_cluster.fit(X_train_resampled, y_cluster_train)  # Use resampled data for training\n",
    "\n",
    "# Evaluate the model for Nutritional Cluster Prediction using cross-validation\n",
    "cv_accuracy_cluster = cross_val_score(svm_cluster, X_train_resampled, y_cluster_train, cv=5, scoring='accuracy')\n",
    "print(\"\\nCross-Validation Accuracy for Nutritional Cluster Prediction:\", cv_accuracy_cluster.mean())\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_cluster_pred = svm_cluster.predict(X_test[numerical_features])\n",
    "accuracy_cluster = accuracy_score(y_cluster_test, y_cluster_pred)\n",
    "\n",
    "print(\"\\nAccuracy for Nutritional Cluster Prediction:\", accuracy_cluster)\n",
    "print(\"\\nClassification Report for Nutritional Cluster Prediction:\\n\", classification_report(y_cluster_test, y_cluster_pred))\n",
    "print(\"\\nConfusion Matrix for Nutritional Cluster Prediction:\\n\", confusion_matrix(y_cluster_test, y_cluster_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4e1f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_15244/1487957648.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['name_tokens'] = X['name_tokens'].apply(lambda x: eval(x))\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_15244/1487957648.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ingredient_tokens'] = X['ingredient_tokens'].apply(lambda x: eval(x))\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_15244/1487957648.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['steps_tokens'] = X['steps_tokens'].apply(lambda x: eval(x))\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_15244/1487957648.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['name_length'] = X['name_tokens'].apply(len)\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_15244/1487957648.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ingredient_count'] = X['ingredient_tokens'].apply(len)\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_15244/1487957648.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['steps_length'] = X['steps_tokens'].apply(len)\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_15244/1487957648.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[numerical_features] = scaler.fit_transform(X[numerical_features])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy for Calorie Level Prediction: 0.40380166771272297\n",
      "Accuracy for Calorie Level Prediction: 0.410933161304799\n",
      "\n",
      "Classification Report for Calorie Level Prediction:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.54      0.51     13934\n",
      "           1       0.39      0.30      0.34     12785\n",
      "           2       0.32      0.36      0.34      8934\n",
      "\n",
      "    accuracy                           0.41     35653\n",
      "   macro avg       0.40      0.40      0.40     35653\n",
      "weighted avg       0.41      0.41      0.41     35653\n",
      "\n",
      "\n",
      "Confusion Matrix for Calorie Level Prediction:\n",
      " [[7585 3544 2805]\n",
      " [5033 3842 3910]\n",
      " [3166 2544 3224]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler  # Import oversampling library\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('nutritional_clustered_data.csv')\n",
    "\n",
    "# Extract features (X) and target variables (y)\n",
    "X = data[['name_tokens', 'ingredient_tokens', 'steps_tokens', 'techniques', 'ingredient_ids']]\n",
    "y_calorie_level = data['calorie_level']\n",
    "y_nutritional_cluster = data['nutritional_cluster']\n",
    "\n",
    "# Tokenization and Preprocessing\n",
    "X['name_tokens'] = X['name_tokens'].apply(lambda x: eval(x))\n",
    "X['ingredient_tokens'] = X['ingredient_tokens'].apply(lambda x: eval(x))\n",
    "X['steps_tokens'] = X['steps_tokens'].apply(lambda x: eval(x))\n",
    "\n",
    "# Feature Engineering\n",
    "X['name_length'] = X['name_tokens'].apply(len)\n",
    "X['ingredient_count'] = X['ingredient_tokens'].apply(len)\n",
    "X['steps_length'] = X['steps_tokens'].apply(len)\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['name_length', 'ingredient_count', 'steps_length']\n",
    "X[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_calorie_train, y_calorie_test, y_cluster_train, y_cluster_test = train_test_split(\n",
    "    X, y_calorie_level, y_nutritional_cluster, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Check for class imbalance and apply oversampling to the training set for both predictions\n",
    "oversampler_calorie = RandomOverSampler(random_state=42)\n",
    "X_train_resampled_calorie, y_calorie_train_resampled = oversampler_calorie.fit_resample(\n",
    "    X_train[numerical_features], y_calorie_train\n",
    ")\n",
    "\n",
    "oversampler_cluster = RandomOverSampler(random_state=42)\n",
    "X_train_resampled_cluster, y_cluster_train_resampled = oversampler_cluster.fit_resample(\n",
    "    X_train[numerical_features], y_cluster_train\n",
    ")\n",
    "\n",
    "# SVM for Calorie Level Prediction with hyperparameter tuning\n",
    "svm_calorie = SVC(C=1.0, kernel='rbf', random_state=42)  # Add hyperparameters for tuning\n",
    "\n",
    "# Fit the model using resampled data\n",
    "svm_calorie.fit(X_train_resampled_calorie, y_calorie_train_resampled)\n",
    "\n",
    "# Evaluate the model for Calorie Level Prediction using cross-validation\n",
    "cv_accuracy_calorie = cross_val_score(\n",
    "    svm_calorie, X_train_resampled_calorie, y_calorie_train_resampled, cv=5, scoring='accuracy'\n",
    ")\n",
    "print(\"Cross-Validation Accuracy for Calorie Level Prediction:\", cv_accuracy_calorie.mean())\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_calorie_pred = svm_calorie.predict(X_test[numerical_features])\n",
    "accuracy_calorie = accuracy_score(y_calorie_test, y_calorie_pred)\n",
    "\n",
    "print(\"Accuracy for Calorie Level Prediction:\", accuracy_calorie)\n",
    "print(\"\\nClassification Report for Calorie Level Prediction:\\n\", classification_report(y_calorie_test, y_calorie_pred))\n",
    "print(\"\\nConfusion Matrix for Calorie Level Prediction:\\n\", confusion_matrix(y_calorie_test, y_calorie_pred))\n",
    "\n",
    "# SVM for Nutritional Cluster Prediction with hyperparameter tuning\n",
    "svm_cluster = SVC(C=1.0, kernel='rbf', random_state=42)  # Add hyperparameters for tuning\n",
    "\n",
    "# Fit the model using resampled data for nutritional cluster prediction\n",
    "svm_cluster.fit(X_train_resampled_cluster, y_cluster_train_resampled)\n",
    "\n",
    "# Evaluate the model for Nutritional Cluster Prediction using cross-validation\n",
    "cv_accuracy_cluster = cross_val_score(\n",
    "    svm_cluster, X_train_resampled_cluster, y_cluster_train_resampled, cv=5, scoring='accuracy'\n",
    ")\n",
    "print(\"\\nCross-Validation Accuracy for Nutritional Cluster Prediction:\", cv_accuracy_cluster.mean())\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_cluster_pred = svm_cluster.predict(X_test[numerical_features])\n",
    "accuracy_cluster = accuracy_score(y_cluster_test, y_cluster_pred)\n",
    "\n",
    "print(\"\\nAccuracy for Nutritional Cluster Prediction:\", accuracy_cluster)\n",
    "print(\"\\nClassification Report for Nutritional Cluster Prediction:\\n\", classification_report(y_cluster_test, y_cluster_pred))\n",
    "print(\"\\nConfusion Matrix for Nutritional Cluster Prediction:\\n\", confusion_matrix(y_cluster_test, y_cluster_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36946df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_16424/2747326744.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['name_tokens'] = X['name_tokens'].apply(lambda x: eval(x))\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_16424/2747326744.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ingredient_tokens'] = X['ingredient_tokens'].apply(lambda x: eval(x))\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_16424/2747326744.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['steps_tokens'] = X['steps_tokens'].apply(lambda x: eval(x))\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_16424/2747326744.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['name_length'] = X['name_tokens'].apply(len)\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_16424/2747326744.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ingredient_count'] = X['ingredient_tokens'].apply(len)\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_16424/2747326744.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['steps_length'] = X['steps_tokens'].apply(len)\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_16424/2747326744.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[numerical_features] = scaler.fit_transform(X[numerical_features])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "BaseSampler.fit_resample() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 41\u001b[0m\n\u001b[1;32m     37\u001b[0m oversampler \u001b[38;5;241m=\u001b[39m RandomOverSampler(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     38\u001b[0m X_train_resampled, y_calorie_train_resampled \u001b[38;5;241m=\u001b[39m oversampler\u001b[38;5;241m.\u001b[39mfit_resample(\n\u001b[1;32m     39\u001b[0m     X_train[numerical_features], y_calorie_train\n\u001b[1;32m     40\u001b[0m )\n\u001b[0;32m---> 41\u001b[0m y_cluster_train_resampled \u001b[38;5;241m=\u001b[39m oversampler\u001b[38;5;241m.\u001b[39mfit_resample(y_cluster_train)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# SVM Hyperparameter Tuning using GridSearchCV\u001b[39;00m\n\u001b[1;32m     44\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n",
      "\u001b[0;31mTypeError\u001b[0m: BaseSampler.fit_resample() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler  # Import oversampling library\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('nutritional_clustered_data.csv')\n",
    "\n",
    "# Extract features (X) and target variables (y)\n",
    "X = data[['name_tokens', 'ingredient_tokens', 'steps_tokens', 'techniques', 'ingredient_ids']]\n",
    "y_calorie_level = data['calorie_level']\n",
    "y_nutritional_cluster = data['nutritional_cluster']\n",
    "\n",
    "# Tokenization and Preprocessing\n",
    "X['name_tokens'] = X['name_tokens'].apply(lambda x: eval(x))\n",
    "X['ingredient_tokens'] = X['ingredient_tokens'].apply(lambda x: eval(x))\n",
    "X['steps_tokens'] = X['steps_tokens'].apply(lambda x: eval(x))\n",
    "\n",
    "# Feature Engineering\n",
    "X['name_length'] = X['name_tokens'].apply(len)\n",
    "X['ingredient_count'] = X['ingredient_tokens'].apply(len)\n",
    "X['steps_length'] = X['steps_tokens'].apply(len)\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['name_length', 'ingredient_count', 'steps_length']\n",
    "X[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_calorie_train, y_calorie_test, y_cluster_train, y_cluster_test = train_test_split(\n",
    "    X, y_calorie_level, y_nutritional_cluster, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Check for class imbalance and apply oversampling to the training set\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_calorie_train_resampled = oversampler.fit_resample(\n",
    "    X_train[numerical_features], y_calorie_train\n",
    ")\n",
    "y_cluster_train_resampled = oversampler.fit_resample(y_cluster_train)\n",
    "\n",
    "# SVM Hyperparameter Tuning using GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "svm_calorie = SVC(random_state=42)\n",
    "grid_search_calorie = GridSearchCV(svm_calorie, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search_calorie.fit(X_train_resampled, y_calorie_train_resampled)\n",
    "\n",
    "# Get the best estimator\n",
    "best_svm_calorie = grid_search_calorie.best_estimator_\n",
    "\n",
    "# Evaluate the model for Calorie Level Prediction using cross-validation\n",
    "cv_accuracy_calorie = cross_val_score(\n",
    "    best_svm_calorie, X_train_resampled, y_calorie_train_resampled, cv=5, scoring='accuracy'\n",
    ")\n",
    "print(\"Cross-Validation Accuracy for Calorie Level Prediction:\", cv_accuracy_calorie.mean())\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_calorie_pred = best_svm_calorie.predict(X_test[numerical_features])\n",
    "accuracy_calorie = accuracy_score(y_calorie_test, y_calorie_pred)\n",
    "\n",
    "print(\"Accuracy for Calorie Level Prediction:\", accuracy_calorie)\n",
    "print(\"\\nClassification Report for Calorie Level Prediction:\\n\", classification_report(y_calorie_test, y_calorie_pred))\n",
    "print(\"\\nConfusion Matrix for Calorie Level Prediction:\\n\", confusion_matrix(y_calorie_test, y_calorie_pred))\n",
    "\n",
    "# SVM Hyperparameter Tuning for Nutritional Cluster Prediction using GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "svm_cluster = SVC(random_state=42)\n",
    "grid_search_cluster = GridSearchCV(svm_cluster, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search_cluster.fit(X_train_resampled, y_cluster_train_resampled)\n",
    "\n",
    "# Get the best estimator\n",
    "best_svm_cluster = grid_search_cluster.best_estimator_\n",
    "\n",
    "# Evaluate the model for Nutritional Cluster Prediction using cross-validation\n",
    "cv_accuracy_cluster = cross_val_score(\n",
    "    best_svm_cluster, X_train_resampled, y_cluster_train_resampled, cv=5, scoring='accuracy'\n",
    ")\n",
    "print(\"\\nCross-Validation Accuracy for Nutritional Cluster Prediction:\", cv_accuracy_cluster.mean())\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_cluster_pred = best_svm_cluster.predict(X_test[numerical_features])\n",
    "accuracy_cluster = accuracy_score(y_cluster_test, y_cluster_pred)\n",
    "\n",
    "print(\"\\nAccuracy for Nutritional Cluster Prediction:\", accuracy_cluster)\n",
    "print(\"\\nClassification Report for Nutritional Cluster Prediction:\\n\", classification_report(y_cluster_test, y_cluster_pred))\n",
    "print(\"\\nConfusion Matrix for Nutritional Cluster Prediction:\\n\", confusion_matrix(y_cluster_test, y_cluster_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35353595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7071a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_16424/3399631106.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['name_tokens'] = X['name_tokens'].apply(lambda x: eval(x))\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_16424/3399631106.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ingredient_tokens'] = X['ingredient_tokens'].apply(lambda x: eval(x))\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_16424/3399631106.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['steps_tokens'] = X['steps_tokens'].apply(lambda x: eval(x))\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_16424/3399631106.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['name_length'] = X['name_tokens'].apply(len)\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_16424/3399631106.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ingredient_count'] = X['ingredient_tokens'].apply(len)\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_16424/3399631106.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['steps_length'] = X['steps_tokens'].apply(len)\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_16424/3399631106.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[numerical_features] = scaler.fit_transform(X[numerical_features])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 210875 elements, new values have 235558 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 41\u001b[0m\n\u001b[1;32m     37\u001b[0m oversampler \u001b[38;5;241m=\u001b[39m RandomOverSampler(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     38\u001b[0m X_train_resampled, y_calorie_train_resampled \u001b[38;5;241m=\u001b[39m oversampler\u001b[38;5;241m.\u001b[39mfit_resample(\n\u001b[1;32m     39\u001b[0m     X_train[numerical_features], y_calorie_train\n\u001b[1;32m     40\u001b[0m )\n\u001b[0;32m---> 41\u001b[0m X_train_resampled, y_cluster_train_resampled \u001b[38;5;241m=\u001b[39m oversampler\u001b[38;5;241m.\u001b[39mfit_resample(\n\u001b[1;32m     42\u001b[0m     X_train_resampled, y_cluster_train\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# SVM Hyperparameter Tuning using GridSearchCV\u001b[39;00m\n\u001b[1;32m     46\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/imblearn/base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_resample(X, y)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/imblearn/base.py:118\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    112\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resample(X, y)\n\u001b[1;32m    114\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    116\u001b[0m )\n\u001b[0;32m--> 118\u001b[0m X_, y_ \u001b[38;5;241m=\u001b[39m arrays_transformer\u001b[38;5;241m.\u001b[39mtransform(output[\u001b[38;5;241m0\u001b[39m], y_)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (X_, y_) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(output) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m (X_, y_, output[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/imblearn/utils/_validation.py:46\u001b[0m, in \u001b[0;36mArraysTransformer.transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     40\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfrom_one(y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_props)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_props[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataframe\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_props[\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     43\u001b[0m ]\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataframe\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# We lost the y.index during resampling. We can safely use X.index to align\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# them.\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m     y\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mindex\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:6218\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6216\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   6217\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[0;32m-> 6218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[1;32m   6219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   6220\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32mproperties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:767\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    766\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 767\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mset_axis(axis, labels)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:227\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_set_axis(axis, new_labels)\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/pandas/core/internals/base.py:85\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 210875 elements, new values have 235558 elements"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler  # Import oversampling library\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('nutritional_clustered_data.csv')\n",
    "\n",
    "# Extract features (X) and target variables (y)\n",
    "X = data[['name_tokens', 'ingredient_tokens', 'steps_tokens', 'techniques', 'ingredient_ids']]\n",
    "y_calorie_level = data['calorie_level']\n",
    "y_nutritional_cluster = data['nutritional_cluster']\n",
    "\n",
    "# Tokenization and Preprocessing\n",
    "X['name_tokens'] = X['name_tokens'].apply(lambda x: eval(x))\n",
    "X['ingredient_tokens'] = X['ingredient_tokens'].apply(lambda x: eval(x))\n",
    "X['steps_tokens'] = X['steps_tokens'].apply(lambda x: eval(x))\n",
    "\n",
    "# Feature Engineering\n",
    "X['name_length'] = X['name_tokens'].apply(len)\n",
    "X['ingredient_count'] = X['ingredient_tokens'].apply(len)\n",
    "X['steps_length'] = X['steps_tokens'].apply(len)\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['name_length', 'ingredient_count', 'steps_length']\n",
    "X[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_calorie_train, y_calorie_test, y_cluster_train, y_cluster_test = train_test_split(\n",
    "    X, y_calorie_level, y_nutritional_cluster, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Check for class imbalance and apply oversampling to the training set\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_calorie_train_resampled = oversampler.fit_resample(\n",
    "    X_train[numerical_features], y_calorie_train\n",
    ")\n",
    "X_train_resampled, y_cluster_train_resampled = oversampler.fit_resample(\n",
    "    X_train_resampled, y_cluster_train\n",
    ")\n",
    "\n",
    "# SVM Hyperparameter Tuning using GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "svm_calorie = SVC(random_state=42)\n",
    "grid_search_calorie = GridSearchCV(svm_calorie, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search_calorie.fit(X_train_resampled, y_calorie_train_resampled)\n",
    "\n",
    "# Get the best estimator\n",
    "best_svm_calorie = grid_search_calorie.best_estimator_\n",
    "\n",
    "# Evaluate the model for Calorie Level Prediction using cross-validation\n",
    "cv_accuracy_calorie = cross_val_score(\n",
    "    best_svm_calorie, X_train_resampled, y_calorie_train_resampled, cv=5, scoring='accuracy'\n",
    ")\n",
    "print(\"Cross-Validation Accuracy for Calorie Level Prediction:\", cv_accuracy_calorie.mean())\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_calorie_pred = best_svm_calorie.predict(X_test[numerical_features])\n",
    "accuracy_calorie = accuracy_score(y_calorie_test, y_calorie_pred)\n",
    "\n",
    "print(\"Accuracy for Calorie Level Prediction:\", accuracy_calorie)\n",
    "print(\"\\nClassification Report for Calorie Level Prediction:\\n\", classification_report(y_calorie_test, y_calorie_pred))\n",
    "print(\"\\nConfusion Matrix for Calorie Level Prediction:\\n\", confusion_matrix(y_calorie_test, y_calorie_pred))\n",
    "\n",
    "# SVM Hyperparameter Tuning for Nutritional Cluster Prediction using GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "svm_cluster = SVC(random_state=42)\n",
    "grid_search_cluster = GridSearchCV(svm_cluster, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search_cluster.fit(X_train_resampled, y_cluster_train_resampled)\n",
    "\n",
    "# Get the best estimator\n",
    "best_svm_cluster = grid_search_cluster.best_estimator_\n",
    "\n",
    "# Evaluate the model for Nutritional Cluster Prediction using cross-validation\n",
    "cv_accuracy_cluster = cross_val_score(\n",
    "    best_svm_cluster, X_train_resampled, y_cluster_train_resampled, cv=5, scoring='accuracy'\n",
    ")\n",
    "print(\"\\nCross-Validation Accuracy for Nutritional Cluster Prediction:\", cv_accuracy_cluster.mean())\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_cluster_pred = best_svm_cluster.predict(X_test[numerical_features])\n",
    "accuracy_cluster = accuracy_score(y_cluster_test, y_cluster_pred)\n",
    "\n",
    "print(\"\\nAccuracy for Nutritional Cluster Prediction:\", accuracy_cluster)\n",
    "print(\"\\nClassification Report for Nutritional Cluster Prediction:\\n\", classification_report(y_cluster_test, y_cluster_pred))\n",
    "print(\"\\nConfusion Matrix for Nutritional Cluster Prediction:\\n\", confusion_matrix(y_cluster_test, y_cluster_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb527191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d56b6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_16424/3225639274.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['name_tokens'] = X['name_tokens'].apply(lambda x: eval(x))\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_16424/3225639274.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ingredient_tokens'] = X['ingredient_tokens'].apply(lambda x: eval(x))\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_16424/3225639274.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['steps_tokens'] = X['steps_tokens'].apply(lambda x: eval(x))\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_16424/3225639274.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['name_length'] = X['name_tokens'].apply(len)\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_16424/3225639274.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ingredient_count'] = X['ingredient_tokens'].apply(len)\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_16424/3225639274.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['steps_length'] = X['steps_tokens'].apply(len)\n",
      "/var/folders/d4/nyf3l8rd78v2b70sry_9hlt40000gn/T/ipykernel_16424/3225639274.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[numerical_features] = scaler.fit_transform(X[numerical_features])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m svm_calorie \u001b[38;5;241m=\u001b[39m SVC(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     48\u001b[0m grid_search_calorie \u001b[38;5;241m=\u001b[39m GridSearchCV(svm_calorie, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m grid_search_calorie\u001b[38;5;241m.\u001b[39mfit(X_train_resampled, y_calorie_train_resampled)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Get the best estimator\u001b[39;00m\n\u001b[1;32m     52\u001b[0m best_svm_calorie \u001b[38;5;241m=\u001b[39m grid_search_calorie\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:936\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    934\u001b[0m refit_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    938\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:250\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    249\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[0;32m--> 250\u001b[0m fit(X, y, sample_weight, solver_type, kernel, random_seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:329\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    315\u001b[0m libsvm\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[1;32m    319\u001b[0m (\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_,\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[0;32m--> 329\u001b[0m ) \u001b[38;5;241m=\u001b[39m libsvm\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    330\u001b[0m     X,\n\u001b[1;32m    331\u001b[0m     y,\n\u001b[1;32m    332\u001b[0m     svm_type\u001b[38;5;241m=\u001b[39msolver_type,\n\u001b[1;32m    333\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;66;03m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001b[39;00m\n\u001b[1;32m    335\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_class_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m    336\u001b[0m     kernel\u001b[38;5;241m=\u001b[39mkernel,\n\u001b[1;32m    337\u001b[0m     C\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC,\n\u001b[1;32m    338\u001b[0m     nu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnu,\n\u001b[1;32m    339\u001b[0m     probability\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobability,\n\u001b[1;32m    340\u001b[0m     degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegree,\n\u001b[1;32m    341\u001b[0m     shrinking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshrinking,\n\u001b[1;32m    342\u001b[0m     tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol,\n\u001b[1;32m    343\u001b[0m     cache_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_size,\n\u001b[1;32m    344\u001b[0m     coef0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef0,\n\u001b[1;32m    345\u001b[0m     gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gamma,\n\u001b[1;32m    346\u001b[0m     epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon,\n\u001b[1;32m    347\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[1;32m    348\u001b[0m     random_seed\u001b[38;5;241m=\u001b[39mrandom_seed,\n\u001b[1;32m    349\u001b[0m )\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('nutritional_clustered_data.csv')\n",
    "\n",
    "# Extract features (X) and target variables (y)\n",
    "X = data[['name_tokens', 'ingredient_tokens', 'steps_tokens', 'techniques', 'ingredient_ids']]\n",
    "y_calorie_level = data['calorie_level']\n",
    "y_nutritional_cluster = data['nutritional_cluster']\n",
    "\n",
    "# Tokenization and Preprocessing\n",
    "X['name_tokens'] = X['name_tokens'].apply(lambda x: eval(x))\n",
    "X['ingredient_tokens'] = X['ingredient_tokens'].apply(lambda x: eval(x))\n",
    "X['steps_tokens'] = X['steps_tokens'].apply(lambda x: eval(x))\n",
    "\n",
    "# Feature Engineering\n",
    "X['name_length'] = X['name_tokens'].apply(len)\n",
    "X['ingredient_count'] = X['ingredient_tokens'].apply(len)\n",
    "X['steps_length'] = X['steps_tokens'].apply(len)\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['name_length', 'ingredient_count', 'steps_length']\n",
    "X[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_calorie_train, y_calorie_test, y_cluster_train, y_cluster_test = train_test_split(\n",
    "    X, y_calorie_level, y_nutritional_cluster, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Check for class imbalance and apply oversampling to the training set\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_calorie_train_resampled = oversampler.fit_resample(\n",
    "    X_train[numerical_features], y_calorie_train\n",
    ")\n",
    "_, y_cluster_train_resampled = oversampler.fit_resample(\n",
    "    X_train[numerical_features], y_cluster_train\n",
    ")\n",
    "\n",
    "# SVM Hyperparameter Tuning using GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "svm_calorie = SVC(random_state=42)\n",
    "grid_search_calorie = GridSearchCV(svm_calorie, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search_calorie.fit(X_train_resampled, y_calorie_train_resampled)\n",
    "\n",
    "# Get the best estimator\n",
    "best_svm_calorie = grid_search_calorie.best_estimator_\n",
    "\n",
    "# Evaluate the model for Calorie Level Prediction using cross-validation\n",
    "cv_accuracy_calorie = cross_val_score(\n",
    "    best_svm_calorie, X_train_resampled, y_calorie_train_resampled, cv=5, scoring='accuracy'\n",
    ")\n",
    "print(\"Cross-Validation Accuracy for Calorie Level Prediction:\", cv_accuracy_calorie.mean())\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_calorie_pred = best_svm_calorie.predict(X_test[numerical_features])\n",
    "accuracy_calorie = accuracy_score(y_calorie_test, y_calorie_pred)\n",
    "\n",
    "print(\"Accuracy for Calorie Level Prediction:\", accuracy_calorie)\n",
    "print(\"\\nClassification Report for Calorie Level Prediction:\\n\", classification_report(y_calorie_test, y_calorie_pred))\n",
    "print(\"\\nConfusion Matrix for Calorie Level Prediction:\\n\", confusion_matrix(y_calorie_test, y_calorie_pred))\n",
    "\n",
    "# SVM Hyperparameter Tuning for Nutritional Cluster Prediction using GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "svm_cluster = SVC(random_state=42)\n",
    "grid_search_cluster = GridSearchCV(svm_cluster, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search_cluster.fit(X_train_resampled, y_cluster_train_resampled)\n",
    "\n",
    "# Get the best estimator\n",
    "best_svm_cluster = grid_search_cluster.best_estimator_\n",
    "\n",
    "# Evaluate the model for Nutritional Cluster Prediction using cross-validation\n",
    "cv_accuracy_cluster = cross_val_score(\n",
    "    best_svm_cluster, X_train_resampled, y_cluster_train_resampled, cv=5, scoring='accuracy'\n",
    ")\n",
    "print(\"\\nCross-Validation Accuracy for Nutritional Cluster Prediction:\", cv_accuracy_cluster.mean())\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_cluster_pred = best_svm_cluster.predict(X_test[numerical_features])\n",
    "accuracy_cluster = accuracy_score(y_cluster_test, y_cluster_pred)\n",
    "\n",
    "print(\"\\nAccuracy for Nutritional Cluster Prediction:\", accuracy_cluster)\n",
    "print(\"\\nClassification Report for Nutritional Cluster Prediction:\\n\", classification_report(y_cluster_test, y_cluster_pred))\n",
    "print(\"\\nConfusion Matrix for Nutritional Cluster Prediction:\\n\", confusion_matrix(y_cluster_test, y_cluster_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fc9894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd77ad4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bbe9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
